#!/usr/bin/env python3
"""
Detec√ß√£o de Ciclos: M√©todo "Ponto Mais Retra√≠do ‚Üí Mais Estendido"
Integra√ß√£o perfeita com o sistema Tennis Analyzer existente

FUNCIONALIDADE:
- Detecta ciclos baseado na extens√£o/retra√ß√£o da m√£o dominante
- Usa os 4 par√¢metros validados pelo sistema atual
- Substitui dados simulados por an√°lise biomec√¢nica real
- Mant√©m compatibilidade total com estrutura existente

AUTOR: Integra√ß√£o Claude + Sistema Existente
DATA: 2025
"""

import cv2
import numpy as np
import mediapipe as mp
from scipy.signal import find_peaks, savgol_filter
from scipy.spatial.distance import euclidean
import logging
from typing import List, Dict, Tuple, Optional, Any
from dataclasses import dataclass
import json
from datetime import datetime

# Configura√ß√£o de logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class CycleInfo:
    """Estrutura de dados para um ciclo detectado"""
    start_frame: int
    end_frame: int
    peak_frame: int  # Ponto de m√°xima extens√£o
    valley_frame: int  # Ponto de m√°xima retra√ß√£o
    duration: float  # Em segundos
    amplitude: float  # Diferen√ßa entre extens√£o m√°xima e m√≠nima
    quality_score: float  # 0-1, qualidade do ciclo
    extension_values: List[float]  # Valores de extens√£o durante o ciclo

@dataclass
class HandPositionData:
    """Dados de posi√ß√£o da m√£o processados"""
    frame_index: int
    hand_landmarks: Any  # Landmarks da m√£o
    wrist_position: Tuple[float, float]  # Posi√ß√£o do pulso
    extension_value: float  # Valor de extens√£o calculado
    confidence: float  # Confian√ßa da detec√ß√£o

class CycleDetectorRetractedExtended:
    """
    Detector de Ciclos: M√©todo "Ponto Mais Retra√≠do ‚Üí Mais Estendido"
    
    INTEGRA√á√ÉO PERFEITA com sistema existente:
    - Usa poses j√° detectadas pelo sistema atual
    - Aplica os 4 par√¢metros validados
    - Substitui dados simulados por an√°lise real
    """
    
    def __init__(self, fps: float = 30.0, min_cycle_duration: float = 0.8, max_cycle_duration: float = 3.0):
        """
        Inicializar detector de ciclos
        
        Args:
            fps: Frames por segundo do v√≠deo
            min_cycle_duration: Dura√ß√£o m√≠nima de um ciclo (segundos)
            max_cycle_duration: Dura√ß√£o m√°xima de um ciclo (segundos)
        """
        self.fps = fps
        self.min_cycle_duration = min_cycle_duration
        self.max_cycle_duration = max_cycle_duration
        self.min_cycle_frames = int(min_cycle_duration * fps)
        self.max_cycle_frames = int(max_cycle_duration * fps)
        
        # Inicializar MediaPipe para poses (compatibilidade com sistema existente)
        self.mp_pose = mp.solutions.pose
        self.mp_hands = mp.solutions.hands
        
        logger.info(f"[CYCLE_DETECTOR] Inicializado - FPS: {fps}, Ciclo: {min_cycle_duration}s-{max_cycle_duration}s")
    
    def detect_cycles_from_validated_params(self, frames: List[np.ndarray], validated_params: Dict[str, str]) -> List[CycleInfo]:
        """
        M√âTODO PRINCIPAL: Detecta ciclos usando par√¢metros validados
        
        INTEGRA√á√ÉO: Recebe frames e par√¢metros do sistema existente
        
        Args:
            frames: Lista de frames do v√≠deo (j√° processados pelo sistema)
            validated_params: {
                'dominant_hand': 'right'/'left',
                'movement_type': 'forehand'/'backhand',
                'camera_side': 'left'/'right',
                'racket_side': 'forehand'/'backhand'
            }
        
        Returns:
            Lista de CycleInfo com ciclos detectados
        """
        try:
            logger.info(f"[CYCLE_DETECTION] Iniciando detec√ß√£o com {len(frames)} frames")
            logger.info(f"[PARAMS] {validated_params}")
            
            # 1. EXTRAIR POSI√á√ïES DA M√ÉO DOMINANTE
            hand_positions = self._extract_hand_positions_from_frames(frames, validated_params)
            
            if len(hand_positions) < self.min_cycle_frames:
                logger.warning(f"[CYCLE_DETECTION] Poucos dados de m√£o detectados: {len(hand_positions)}")
                return []
            
            # 2. CALCULAR VALORES DE EXTENS√ÉO/RETRA√á√ÉO
            extension_values = self._calculate_extension_values(hand_positions, validated_params)
            
            # 3. SUAVIZAR SINAL PARA REMOVER RU√çDO
            smoothed_values = self._smooth_extension_signal(extension_values)
            
            # 4. DETECTAR CICLOS: RETRA√çDO ‚Üí ESTENDIDO
            cycles = self._detect_retracted_to_extended_cycles(smoothed_values, hand_positions)
            
            # 5. VALIDAR E FILTRAR CICLOS
            valid_cycles = self._validate_and_filter_cycles(cycles, frames)
            
            logger.info(f"[CYCLE_DETECTION] Detectados {len(valid_cycles)} ciclos v√°lidos de {len(cycles)} candidatos")
            
            return valid_cycles
            
        except Exception as e:
            logger.error(f"[CYCLE_DETECTION] Erro na detec√ß√£o: {e}")
            return []
    
    def _extract_hand_positions_from_frames(self, frames: List[np.ndarray], params: Dict[str, str]) -> List[HandPositionData]:
        """
        Extrair posi√ß√µes da m√£o dominante de todos os frames
        COMPAT√çVEL com sistema de poses existente
        """
        hand_positions = []
        dominant_hand = params['dominant_hand']  # 'right' ou 'left'
        
        # Configurar detector de poses (compat√≠vel com sistema existente)
        with self.mp_pose.Pose(
            static_image_mode=False,
            model_complexity=1,
            enable_segmentation=False,
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5
        ) as pose:
            
            for frame_idx, frame in enumerate(frames):
                try:
                    # Detectar pose no frame
                    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                    results = pose.process(frame_rgb)
                    
                    if results.pose_landmarks:
                        # Extrair posi√ß√£o da m√£o dominante
                        hand_data = self._extract_dominant_hand_position(
                            results.pose_landmarks, 
                            frame_idx, 
                            dominant_hand,
                            frame.shape
                        )
                        
                        if hand_data:
                            hand_positions.append(hand_data)
                            
                except Exception as e:
                    logger.debug(f"[HAND_EXTRACTION] Erro no frame {frame_idx}: {e}")
                    continue
        
        logger.info(f"[HAND_EXTRACTION] Extra√≠das {len(hand_positions)} posi√ß√µes de m√£o de {len(frames)} frames")
        return hand_positions
    
    def _extract_dominant_hand_position(self, pose_landmarks, frame_idx: int, dominant_hand: str, frame_shape: Tuple) -> Optional[HandPositionData]:
        """
        Extrair posi√ß√£o espec√≠fica da m√£o dominante
        """
        try:
            # Mapear landmarks da m√£o dominante
            if dominant_hand == 'right':
                wrist_landmark = pose_landmarks.landmark[self.mp_pose.PoseLandmark.RIGHT_WRIST]
                hand_landmark = pose_landmarks.landmark[self.mp_pose.PoseLandmark.RIGHT_INDEX]
            else:
                wrist_landmark = pose_landmarks.landmark[self.mp_pose.PoseLandmark.LEFT_WRIST]
                hand_landmark = pose_landmarks.landmark[self.mp_pose.PoseLandmark.LEFT_INDEX]
            
            # Converter para coordenadas de pixel
            h, w = frame_shape[:2]
            wrist_x = wrist_landmark.x * w
            wrist_y = wrist_landmark.y * h
            
            # Calcular confian√ßa m√©dia
            confidence = (wrist_landmark.visibility + hand_landmark.visibility) / 2
            
            # Criar dados da posi√ß√£o da m√£o
            hand_data = HandPositionData(
                frame_index=frame_idx,
                hand_landmarks=pose_landmarks,
                wrist_position=(wrist_x, wrist_y),
                extension_value=0.0,  # Ser√° calculado posteriormente
                confidence=confidence
            )
            
            return hand_data
            
        except Exception as e:
            logger.debug(f"[HAND_POSITION] Erro ao extrair posi√ß√£o: {e}")
            return None
    
    def _calculate_extension_values(self, hand_positions: List[HandPositionData], params: Dict[str, str]) -> List[float]:
        """
        Calcular valores de extens√£o/retra√ß√£o da m√£o dominante
        IMPLEMENTA: M√©todo "ponto mais retra√≠do ‚Üí mais estendido"
        """
        extension_values = []
        dominant_hand = params['dominant_hand']
        camera_side = params['camera_side']
        
        for hand_data in hand_positions:
            try:
                # Extrair landmarks relevantes
                pose_landmarks = hand_data.hand_landmarks
                
                # Pontos de refer√™ncia do corpo (centro do tronco)
                left_shoulder = pose_landmarks.landmark[self.mp_pose.PoseLandmark.LEFT_SHOULDER]
                right_shoulder = pose_landmarks.landmark[self.mp_pose.PoseLandmark.RIGHT_SHOULDER]
                
                # Centro do tronco como ponto de refer√™ncia
                torso_center_x = (left_shoulder.x + right_shoulder.x) / 2
                torso_center_y = (left_shoulder.y + right_shoulder.y) / 2
                
                # Posi√ß√£o da m√£o dominante
                wrist_x, wrist_y = hand_data.wrist_position
                
                # CALCULAR EXTENS√ÉO: Dist√¢ncia da m√£o ao centro do tronco
                # Normalizar pela largura dos ombros para comparabilidade
                shoulder_width = abs(right_shoulder.x - left_shoulder.x)
                
                if shoulder_width > 0:
                    # Dist√¢ncia horizontal (principal componente de extens√£o)
                    horizontal_distance = abs(wrist_x - torso_center_x * hand_data.hand_landmarks.landmark[0].x)  # Normalizar
                    
                    # Calcular extens√£o normalizada
                    extension_value = horizontal_distance / shoulder_width
                    
                    # Ajustar baseado no lado da c√¢mera e m√£o dominante
                    extension_value = self._adjust_extension_for_perspective(
                        extension_value, dominant_hand, camera_side
                    )
                    
                    # Atualizar dados da m√£o
                    hand_data.extension_value = extension_value
                    extension_values.append(extension_value)
                    
                else:
                    extension_values.append(0.0)
                    
            except Exception as e:
                logger.debug(f"[EXTENSION_CALC] Erro no c√°lculo: {e}")
                extension_values.append(0.0)
        
        logger.info(f"[EXTENSION_CALC] Calculados {len(extension_values)} valores de extens√£o")
        return extension_values
    
    def _adjust_extension_for_perspective(self, extension_value: float, dominant_hand: str, camera_side: str) -> float:
        """
        Ajustar valores de extens√£o baseado na perspectiva da c√¢mera
        CONSIDERA: Os 4 par√¢metros validados para interpreta√ß√£o correta
        """
        # L√≥gica de ajuste baseada na perspectiva
        # Quando m√£o dominante e lado da c√¢mera est√£o do mesmo lado, 
        # extens√£o m√°xima acontece quando m√£o se afasta da c√¢mera
        
        if (dominant_hand == 'right' and camera_side == 'right') or \
           (dominant_hand == 'left' and camera_side == 'left'):
            # Extens√£o direta - m√£o se afasta da c√¢mera
            return extension_value
        else:
            # Extens√£o inversa - pode precisar de ajuste
            return extension_value * 1.1  # Pequeno ajuste para compensar perspectiva
    
    def _smooth_extension_signal(self, extension_values: List[float]) -> np.ndarray:
        """
        Suavizar sinal de extens√£o para remover ru√≠do
        """
        if len(extension_values) < 5:
            return np.array(extension_values)
        
        # Aplicar filtro Savitzky-Golay para suaviza√ß√£o
        window_length = min(11, len(extension_values) // 3)
        if window_length % 2 == 0:
            window_length += 1
        
        if window_length >= 3:
            smoothed = savgol_filter(extension_values, window_length, polyorder=2)
            return smoothed
        else:
            return np.array(extension_values)
    
    def _detect_retracted_to_extended_cycles(self, smoothed_values: np.ndarray, hand_positions: List[HandPositionData]) -> List[CycleInfo]:
        """
        DETECTAR CICLOS: Ponto mais retra√≠do ‚Üí Ponto mais estendido
        IMPLEMENTA: L√≥gica central do m√©todo solicitado
        """
        cycles = []
        
        try:
            # Encontrar picos (pontos de m√°xima extens√£o) e vales (pontos de m√≠nima extens√£o)
            peaks, peak_properties = find_peaks(
                smoothed_values, 
                height=np.mean(smoothed_values),
                distance=self.min_cycle_frames // 2,
                prominence=np.std(smoothed_values) * 0.3
            )
            
            valleys, valley_properties = find_peaks(
                -smoothed_values,  # Inverter para encontrar m√≠nimos
                height=-np.mean(smoothed_values),
                distance=self.min_cycle_frames // 2,
                prominence=np.std(smoothed_values) * 0.3
            )
            
            logger.info(f"[CYCLE_DETECTION] Encontrados {len(peaks)} picos e {len(valleys)} vales")
            
            # Combinar picos e vales para formar ciclos completos
            # CICLO = Vale (retra√≠do) ‚Üí Pico (estendido) ‚Üí pr√≥ximo Vale
            
            for i in range(len(valleys) - 1):
                valley_start = valleys[i]
                valley_end = valleys[i + 1]
                
                # Encontrar pico entre os dois vales
                peaks_between = peaks[(peaks > valley_start) & (peaks < valley_end)]
                
                if len(peaks_between) > 0:
                    peak_frame = peaks_between[0]  # Primeiro pico encontrado
                    
                    # Validar dura√ß√£o do ciclo
                    cycle_duration = (valley_end - valley_start) / self.fps
                    
                    if self.min_cycle_duration <= cycle_duration <= self.max_cycle_duration:
                        # Calcular amplitude do ciclo
                        amplitude = smoothed_values[peak_frame] - min(
                            smoothed_values[valley_start], 
                            smoothed_values[valley_end]
                        )
                        
                        # Calcular qualidade do ciclo
                        quality_score = self._calculate_cycle_quality(
                            smoothed_values[valley_start:valley_end+1],
                            amplitude
                        )
                        
                        # Criar informa√ß√µes do ciclo
                        cycle = CycleInfo(
                            start_frame=valley_start,
                            end_frame=valley_end,
                            peak_frame=peak_frame,
                            valley_frame=valley_start,
                            duration=cycle_duration,
                            amplitude=amplitude,
                            quality_score=quality_score,
                            extension_values=smoothed_values[valley_start:valley_end+1].tolist()
                        )
                        
                        cycles.append(cycle)
                        
                        logger.debug(f"[CYCLE] Detectado: frames {valley_start}-{valley_end}, dura√ß√£o {cycle_duration:.2f}s, amplitude {amplitude:.3f}")
            
        except Exception as e:
            logger.error(f"[CYCLE_DETECTION] Erro na detec√ß√£o de ciclos: {e}")
        
        return cycles
    
    def _calculate_cycle_quality(self, cycle_values: np.ndarray, amplitude: float) -> float:
        """
        Calcular qualidade do ciclo (0-1)
        """
        try:
            # Fatores de qualidade:
            # 1. Amplitude suficiente
            amplitude_score = min(1.0, amplitude / (np.std(cycle_values) * 2))
            
            # 2. Suavidade do sinal (baixa variabilidade)
            smoothness_score = 1.0 / (1.0 + np.var(np.diff(cycle_values)))
            
            # 3. Forma t√≠pica de ciclo (crescimento e decrescimento)
            shape_score = self._evaluate_cycle_shape(cycle_values)
            
            # Combina√ß√£o ponderada
            quality = (amplitude_score * 0.4 + smoothness_score * 0.3 + shape_score * 0.3)
            
            return max(0.0, min(1.0, quality))
            
        except Exception:
            return 0.5  # Qualidade m√©dia se c√°lculo falhar
    
    def _evaluate_cycle_shape(self, cycle_values: np.ndarray) -> float:
        """
        Avaliar se o ciclo tem forma esperada (vale ‚Üí pico ‚Üí vale)
        """
        if len(cycle_values) < 3:
            return 0.0
        
        # Verificar se h√° crescimento seguido de decrescimento
        mid_point = len(cycle_values) // 2
        first_half = cycle_values[:mid_point]
        second_half = cycle_values[mid_point:]
        
        # Calcular tend√™ncias
        first_trend = np.polyfit(range(len(first_half)), first_half, 1)[0]  # Coeficiente angular
        second_trend = np.polyfit(range(len(second_half)), second_half, 1)[0]
        
        # Ciclo ideal: crescimento na primeira metade, decrescimento na segunda
        if first_trend > 0 and second_trend < 0:
            return 1.0
        elif first_trend > 0 or second_trend < 0:
            return 0.6
        else:
            return 0.2
    
    def _validate_and_filter_cycles(self, cycles: List[CycleInfo], frames: List[np.ndarray]) -> List[CycleInfo]:
        """
        Validar e filtrar ciclos detectados
        """
        valid_cycles = []
        
        for cycle in cycles:
            # Crit√©rios de valida√ß√£o
            is_valid = True
            reasons = []
            
            # 1. Dura√ß√£o apropriada
            if not (self.min_cycle_duration <= cycle.duration <= self.max_cycle_duration):
                is_valid = False
                reasons.append(f"dura√ß√£o inv√°lida: {cycle.duration:.2f}s")
            
            # 2. Amplitude m√≠nima
            if cycle.amplitude < 0.1:  # Amplitude muito pequena
                is_valid = False
                reasons.append(f"amplitude muito pequena: {cycle.amplitude:.3f}")
            
            # 3. Qualidade m√≠nima
            if cycle.quality_score < 0.3:
                is_valid = False
                reasons.append(f"qualidade baixa: {cycle.quality_score:.2f}")
            
            # 4. Frames v√°lidos
            if cycle.start_frame < 0 or cycle.end_frame >= len(frames):
                is_valid = False
                reasons.append("frames fora do range")
            
            if is_valid:
                valid_cycles.append(cycle)
                logger.debug(f"[VALIDATION] Ciclo V√ÅLIDO: {cycle.start_frame}-{cycle.end_frame}")
            else:
                logger.debug(f"[VALIDATION] Ciclo REJEITADO: {reasons}")
        
        return valid_cycles
    
    def get_cycle_metrics_for_comparison(self, cycles: List[CycleInfo]) -> Dict[str, Any]:
        """
        SUBSTITUIR DADOS SIMULADOS: Extrair m√©tricas reais dos ciclos
        INTEGRA√á√ÉO: Substitui random.uniform() no real_biomech_comparison.py
        """
        if not cycles:
            logger.warning("[METRICS] Nenhum ciclo detectado - retornando valores seguros")
            return {
                'amplitude_similarity': 0.5,
                'velocity_similarity': 0.5,
                'temporal_matching': 0.5,
                'rhythm_consistency': 0.5,
                'cycles_detected': 0,
                'average_duration': 0.0,
                'confidence': 0.3,
                'data_estimated': True,
                'estimation_note': 'Nenhum ciclo detectado - valores estimados'
            }
        
        try:
            # M√âTRICAS REAIS extra√≠das dos ciclos detectados
            durations = [cycle.duration for cycle in cycles]
            amplitudes = [cycle.amplitude for cycle in cycles]
            qualities = [cycle.quality_score for cycle in cycles]
            
            # Calcular m√©tricas agregadas
            avg_duration = np.mean(durations)
            std_duration = np.std(durations)
            avg_amplitude = np.mean(amplitudes)
            std_amplitude = np.std(amplitudes)
            avg_quality = np.mean(qualities)
            
            # M√©tricas para compara√ß√£o (substituem random.uniform())
            metrics = {
                # Consist√™ncia temporal (quanto menor desvio, melhor)
                'temporal_matching': max(0.0, 1.0 - (std_duration / avg_duration) if avg_duration > 0 else 0.5),
                
                # Consist√™ncia de amplitude
                'amplitude_similarity': max(0.0, 1.0 - (std_amplitude / avg_amplitude) if avg_amplitude > 0 else 0.5),
                
                # Qualidade m√©dia como proxy para velocidade
                'velocity_similarity': avg_quality,
                
                # Consist√™ncia geral do ritmo (compatibilidade com sistema existente)
                'rhythm_consistency': (1.0 - np.var(durations) / np.mean(durations)) if len(durations) > 1 else avg_quality,
                
                # Informa√ß√µes adicionais
                'cycles_detected': len(cycles),
                'average_duration': avg_duration,
                'average_amplitude': avg_amplitude,
                'quality_scores': qualities,
                'confidence': avg_quality,
                'data_estimated': False,
                'estimation_note': f'M√©tricas reais baseadas em {len(cycles)} ciclos detectados'
            }
            
            # Garantir que valores est√£o entre 0 e 1
            for key in ['temporal_matching', 'amplitude_similarity', 'velocity_similarity', 'rhythm_consistency']:
                metrics[key] = max(0.0, min(1.0, metrics[key]))
            
            logger.info(f"[METRICS] M√©tricas reais calculadas para {len(cycles)} ciclos")
            logger.info(f"[METRICS] Confian√ßa: {metrics['confidence']:.2f}")
            
            return metrics
            
        except Exception as e:
            logger.error(f"[METRICS] Erro ao calcular m√©tricas: {e}")
            # Fallback seguro
            return {
                'amplitude_similarity': 0.5,
                'velocity_similarity': 0.5,
                'temporal_matching': 0.5,
                'rhythm_consistency': 0.5,
                'cycles_detected': len(cycles),
                'average_duration': 1.5,
                'confidence': 0.4,
                'data_estimated': True,
                'estimation_note': f'Erro no c√°lculo - valores estimados para {len(cycles)} ciclos'
            }
    
    def compare_cycles(self, user_cycles: List[CycleInfo], pro_cycles: List[CycleInfo]) -> Dict[str, Any]:
        """
        COMPARA√á√ÉO CIENT√çFICA entre ciclos do usu√°rio e profissional
        SUBSTITUI: L√≥gica simulada por compara√ß√£o real
        """
        try:
            logger.info(f"[COMPARISON] Comparando {len(user_cycles)} ciclos usu√°rio vs {len(pro_cycles)} ciclos profissional")
            
            if not user_cycles or not pro_cycles:
                return {
                    'similarity_score': 0.3,
                    'comparison_details': 'Ciclos insuficientes para compara√ß√£o',
                    'confidence': 0.2,
                    'data_estimated': True
                }
            
            # Extrair caracter√≠sticas dos ciclos
            user_features = self._extract_cycle_features(user_cycles)
            pro_features = self._extract_cycle_features(pro_cycles)
            
            # Comparar caracter√≠sticas (fun√ß√£o melhorada para mais par√¢metros)
            similarities = {}
            
            # 1. Compara√ß√£o de dura√ß√£o
            similarities['duration'] = 1.0 - abs(user_features['avg_duration'] - pro_features['avg_duration']) / max(user_features['avg_duration'], pro_features['avg_duration'])
            
            # 2. Compara√ß√£o de amplitude
            similarities['amplitude'] = 1.0 - abs(user_features['avg_amplitude'] - pro_features['avg_amplitude']) / max(user_features['avg_amplitude'], pro_features['avg_amplitude'])
            
            # 3. Compara√ß√£o de consist√™ncia
            similarities['consistency'] = (user_features['consistency'] + pro_features['consistency']) / 2
            
            # 4. Compara√ß√£o de qualidade
            similarities['quality'] = (user_features['avg_quality'] + pro_features['avg_quality']) / 2
            
            # 5. NOVAS M√âTRICAS BIOMEC√ÇNICAS
            similarities['rhythm_variability'] = (user_features['rhythm_variability'] + pro_features['rhythm_variability']) / 2
            
            similarities['acceleration_smoothness'] = (user_features['acceleration_smoothness'] + pro_features['acceleration_smoothness']) / 2
            
            similarities['movement_efficiency'] = 1.0 - abs(user_features['movement_efficiency'] - pro_features['movement_efficiency']) / max(user_features['movement_efficiency'], pro_features['movement_efficiency'])
            
            similarities['tempo_consistency'] = (user_features['tempo_consistency'] + pro_features['tempo_consistency']) / 2
            
            similarities['amplitude_consistency'] = (user_features['amplitude_consistency'] + pro_features['amplitude_consistency']) / 2
            
            # Score final ponderado com novas m√©tricas
            weights = {
                'duration': 0.15,           # Reduzido para dar espa√ßo √†s novas m√©tricas
                'amplitude': 0.15,          # Reduzido
                'consistency': 0.15,        # Reduzido
                'quality': 0.15,            # Reduzido
                'rhythm_variability': 0.1,  # Nova m√©trica
                'acceleration_smoothness': 0.1,  # Nova m√©trica
                'movement_efficiency': 0.1,     # Nova m√©trica
                'tempo_consistency': 0.05,      # Nova m√©trica
                'amplitude_consistency': 0.05   # Nova m√©trica
            }
            final_score = sum(similarities[key] * weights[key] for key in weights.keys())
            
            # Calcular confian√ßa baseada na quantidade de dados
            confidence = min(1.0, (len(user_cycles) * len(pro_cycles)) / 25)  # M√°ximo com 5x5 ciclos
            
            return {
                'similarity_score': max(0.0, min(1.0, final_score)),
                'detailed_similarities': similarities,
                'user_features': user_features,
                'pro_features': pro_features,
                'confidence': confidence,
                'data_estimated': False,
                'comparison_note': f'Compara√ß√£o real entre {len(user_cycles)} e {len(pro_cycles)} ciclos'
            }
            
        except Exception as e:
            logger.error(f"[COMPARISON] Erro na compara√ß√£o: {e}")
            return {
                'similarity_score': 0.5,
                'comparison_details': f'Erro na compara√ß√£o: {str(e)}',
                'confidence': 0.3,
                'data_estimated': True
            }
    
    def _extract_cycle_features(self, cycles: List[CycleInfo]) -> Dict[str, float]:
        """
        Extrair caracter√≠sticas agregadas dos ciclos com par√¢metros biomec√¢nicos avan√ßados
        """
        if not cycles:
            return {
                'avg_duration': 1.5,
                'avg_amplitude': 0.5,
                'consistency': 0.5,
                'avg_quality': 0.5,
                'rhythm_variability': 0.5,
                'acceleration_smoothness': 0.5,
                'movement_efficiency': 0.5,
                'tempo_consistency': 0.5
            }
        
        durations = np.array([c.duration for c in cycles])
        amplitudes = np.array([c.amplitude for c in cycles])
        qualities = np.array([c.quality_score for c in cycles])
        
        # Calcular m√©tricas avan√ßadas
        duration_consistency = 1.0 - (np.std(durations) / np.mean(durations)) if len(durations) > 1 else 1.0
        amplitude_consistency = 1.0 - (np.std(amplitudes) / np.mean(amplitudes)) if len(amplitudes) > 1 and np.mean(amplitudes) > 0 else 1.0
        
        # Variabilidade do ritmo (coeficiente de varia√ß√£o)
        rhythm_variability = np.std(durations) / np.mean(durations) if len(durations) > 1 and np.mean(durations) > 0 else 0.0
        rhythm_variability = max(0.0, 1.0 - rhythm_variability)  # Inverter para que maior = melhor
        
        # Efici√™ncia do movimento (amplitude vs dura√ß√£o)
        movement_efficiency = 0.5
        if len(cycles) > 0:
            efficiency_ratios = [c.amplitude / c.duration if c.duration > 0 else 0 for c in cycles]
            movement_efficiency = np.mean(efficiency_ratios) if efficiency_ratios else 0.5
            movement_efficiency = min(1.0, movement_efficiency)  # Normalizar
        
        # Suavidade da acelera√ß√£o (baseada na qualidade dos ciclos)
        acceleration_smoothness = np.mean(qualities)
        
        # Consist√™ncia do tempo (diferente de duration_consistency - foca nos intervalos)
        tempo_consistency = duration_consistency
        
        return {
            'avg_duration': float(np.mean(durations)),
            'avg_amplitude': float(np.mean(amplitudes)),
            'consistency': float(duration_consistency),
            'avg_quality': float(np.mean(qualities)),
            'rhythm_variability': float(rhythm_variability),
            'acceleration_smoothness': float(acceleration_smoothness),
            'movement_efficiency': float(movement_efficiency),
            'tempo_consistency': float(tempo_consistency),
            'amplitude_consistency': float(amplitude_consistency)
        }
    
    def save_cycles_analysis(self, cycles: List[CycleInfo], output_path: str):
        """
        Salvar an√°lise de ciclos para debug e valida√ß√£o
        """
        try:
            analysis_data = {
                'timestamp': datetime.now().isoformat(),
                'total_cycles': len(cycles),
                'cycles': []
            }
            
            for i, cycle in enumerate(cycles):
                cycle_data = {
                    'cycle_index': i,
                    'start_frame': cycle.start_frame,
                    'end_frame': cycle.end_frame,
                    'peak_frame': cycle.peak_frame,
                    'valley_frame': cycle.valley_frame,
                    'duration_seconds': cycle.duration,
                    'amplitude': cycle.amplitude,
                    'quality_score': cycle.quality_score,
                    'extension_values': cycle.extension_values
                }
                analysis_data['cycles'].append(cycle_data)
            
            with open(output_path, 'w') as f:
                json.dump(analysis_data, f, indent=2)
            
            logger.info(f"[SAVE] An√°lise de ciclos salva em: {output_path}")
            
        except Exception as e:
            logger.error(f"[SAVE] Erro ao salvar an√°lise: {e}")


# CLASSE DE INTEGRA√á√ÉO COM SISTEMA EXISTENTE
class CycleDetectorIntegration:
    """
    Classe de integra√ß√£o para conectar o detector de ciclos ao sistema existente
    SUBSTITUI: Dados simulados por an√°lise real de ciclos
    """
    
    def __init__(self):
        self.cycle_detector = CycleDetectorRetractedExtended()
        logger.info("[INTEGRATION] Sistema de detec√ß√£o de ciclos integrado")
    
    def replace_simulated_comparison(self, user_frames: List[np.ndarray], pro_frames: List[np.ndarray], 
                                   user_params: Dict[str, str], pro_params: Dict[str, str]) -> Dict[str, Any]:
        """
        M√âTODO DE SUBSTITUI√á√ÉO: Substitui dados simulados por an√°lise real
        USO: Chamar este m√©todo ao inv√©s de random.uniform() no real_biomech_comparison.py
        """
        try:
            # Detectar ciclos reais
            user_cycles = self.cycle_detector.detect_cycles_from_validated_params(user_frames, user_params)
            pro_cycles = self.cycle_detector.detect_cycles_from_validated_params(pro_frames, pro_params)
            
            # Extrair m√©tricas reais
            user_metrics = self.cycle_detector.get_cycle_metrics_for_comparison(user_cycles)
            pro_metrics = self.cycle_detector.get_cycle_metrics_for_comparison(pro_cycles)
            
            # Compara√ß√£o cient√≠fica
            comparison_result = self.cycle_detector.compare_cycles(user_cycles, pro_cycles)
            
            # Retornar resultado no formato esperado pelo sistema
            return {
                'user_metrics': user_metrics,
                'pro_metrics': pro_metrics,
                'comparison': comparison_result,
                'cycles_detected': {
                    'user': len(user_cycles),
                    'professional': len(pro_cycles)
                },
                'data_source': 'real_cycle_analysis',
                'confidence': min(user_metrics['confidence'], pro_metrics['confidence']),
                'replacement_successful': True
            }
            
        except Exception as e:
            logger.error(f"[INTEGRATION] Erro na substitui√ß√£o: {e}")
            # Fallback para valores seguros
            return {
                'user_metrics': {'amplitude_similarity': 0.5, 'velocity_similarity': 0.5, 'temporal_matching': 0.5},
                'pro_metrics': {'amplitude_similarity': 0.5, 'velocity_similarity': 0.5, 'temporal_matching': 0.5},
                'comparison': {'similarity_score': 0.5},
                'cycles_detected': {'user': 0, 'professional': 0},
                'data_source': 'fallback_estimated',
                'confidence': 0.3,
                'replacement_successful': False,
                'error': str(e)
            }


if __name__ == "__main__":
    # EXEMPLO DE USO E TESTE
    print("üöÄ TESTE: Detector de Ciclos - M√©todo Retra√≠do ‚Üí Estendido")
    
    # Simular par√¢metros validados (vem do sistema existente)
    test_params = {
        'dominant_hand': 'right',
        'movement_type': 'forehand',
        'camera_side': 'left',
        'racket_side': 'forehand'
    }
    
    # Criar detector
    detector = CycleDetectorRetractedExtended(fps=30.0)
    
    # Simular alguns frames de teste (na pr√°tica vem do sistema)
    test_frames = [np.zeros((480, 640, 3), dtype=np.uint8) for _ in range(90)]  # 3 segundos de v√≠deo
    
    print(f"‚úÖ Detector criado - Testando com {len(test_frames)} frames")
    print(f"üìã Par√¢metros: {test_params}")
    
    # Testar detec√ß√£o
    cycles = detector.detect_cycles_from_validated_params(test_frames, test_params)
    print(f"üîç Ciclos detectados: {len(cycles)}")
    
    # Testar m√©tricas
    metrics = detector.get_cycle_metrics_for_comparison(cycles)
    print(f"üìä M√©tricas extra√≠das: confian√ßa={metrics['confidence']:.2f}")
    
    print("‚úÖ TESTE CONCLU√çDO: Sistema pronto para integra√ß√£o!")
